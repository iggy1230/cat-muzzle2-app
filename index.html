<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>Cat Muzzle AI - Stable Anchor v109</title>
    <style>
        body { font-family: sans-serif; background: #0a0a0a; color: #eee; text-align: center; margin: 0; padding: 20px; }
        .card { background: #1a1a1a; padding: 25px; border-radius: 24px; max-width: 850px; margin: auto; box-shadow: 0 10px 40px rgba(0,0,0,0.5); border: 1px solid #333; }
        #log { background: #000; color: #00ff66; font-family: monospace; font-size: 11px; padding: 10px; height: 100px; overflow-y: auto; text-align: left; border-radius: 12px; margin-bottom: 20px; border: 1px solid #222; white-space: pre-wrap; }
        .preview-box { position: relative; width: 100%; background: #000; border-radius: 12px; border: 2px solid #444; overflow: hidden; display: flex; justify-content: center; align-items: center; min-height: 400px; }
        canvas { width: 100%; height: auto; display: block; }
        .btn { padding: 16px 32px; background: #6200ee; color: white; border: none; border-radius: 12px; font-weight: bold; cursor: pointer; font-size: 16px; width: 85%; margin: 10px 0; }
        .btn:disabled { background: #333; color: #777; cursor: wait; }
        .progress-box { width: 85%; margin: 15px auto; display: none; }
        .progress-bar { width: 100%; background: #333; height: 10px; border-radius: 5px; overflow: hidden; }
        #progressFill { width: 0%; background: #00e676; height: 100%; transition: width 0.2s; }
    </style>
</head>
<body>
    <div class="card">
        <h2 style="margin-top:0;">ğŸ± CAT MUZZLE AI <span style="font-size:12px; color:#7c4dff;">v109 STABLE-SMOOTH</span></h2>
        <div id="log">ãƒ­ã‚°: ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ä¸­...</div>
        
        <input type="file" id="fileInput" accept="image/*,video/*" hidden>
        <button id="uploadBtn" class="btn" disabled>ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...</button>

        <div class="progress-box" id="progressBox">
            <div class="progress-bar"><div id="progressFill"></div></div>
            <div id="progressLabel" style="font-size:14px; margin-top:8px; color:#00e676; font-weight:bold;">å‹•ç”»ã®å§¿å‹¢ã‚’ç²¾å¯†ã‚¹ã‚­ãƒ£ãƒ³ä¸­...</div>
        </div>

        <div class="preview-box">
            <canvas id="canvas"></canvas>
            <video id="video" playsinline muted style="display:none;"></video>
        </div>

        <button id="downloadBtn" class="btn" style="background:#00c853; display:none;">ğŸ“¥ ã‚«ãƒ¡ãƒ©ãƒ­ãƒ¼ãƒ«ã¸ä¿å­˜ï¼ˆéŸ³å£°å…¥ã‚Šï¼‰</button>
    </div>

    <script type="module">
        import { FaceLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";

        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const video = document.getElementById('video');
        const fileInput = document.getElementById('fileInput');
        const uploadBtn = document.getElementById('uploadBtn');
        const downloadBtn = document.getElementById('downloadBtn');
        const progressBox = document.getElementById('progressBox');
        const progressFill = document.getElementById('progressFill');
        const progressLabel = document.getElementById('progressLabel');
        const logArea = document.getElementById('log');

        let faceLandmarker, muzzleImg = new Image(); muzzleImg.src = "muzzle.png"; 
        let frameSequence = []; 
        const SCAN_FPS = 12;

        function addLog(msg) { logArea.innerText += `> ${msg}\n`; logArea.scrollTop = logArea.scrollHeight; }

        async function init() {
            try {
                const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
                faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
                    baseOptions: { modelAssetPath: `./models/face_landmarker.task`, delegate: "GPU" },
                    runningMode: "IMAGE", numFaces: 1, minFaceDetectionConfidence: 0.1
                });
                addLog("æº–å‚™å®Œäº†ã€‚ç‰©ç†åˆ¶ç´„ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æœ‰åŠ¹ã€‚");
                uploadBtn.disabled = false; uploadBtn.innerText = "å‹•ç”»ã‚’é¸æŠã—ã¦è§£æé–‹å§‹";
                uploadBtn.onclick = () => fileInput.click();
            } catch (e) { addLog("åˆæœŸåŒ–å¤±æ•—: " + e.message); }
        }

        fileInput.onchange = (e) => {
            const file = e.target.files[0];
            if (!file) return;
            downloadBtn.style.display = "none";
            startStableSmoothScan(URL.createObjectURL(file));
        };

        // --- 1. ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ»ã‚¢ãƒ³ã‚«ãƒ¼è§£æãƒ—ãƒ­ã‚»ã‚¹ ---
        async function startStableSmoothScan(url) {
            addLog("æ‰‹é †1: å‹•ç”»ã®æœ€å¾Œã‹ã‚‰ã€æ­£è§£ã®å ´æ‰€ã€ã‚’ç‰¹å®šã—ã¾ã™...");
            video.src = url; video.load();
            video.onloadedmetadata = async () => {
                canvas.width = video.videoWidth; canvas.height = video.videoHeight;
                frameSequence = []; progressBox.style.display = "block";
                
                // æœ€å¾Œã‹ã‚‰ã‚¢ãƒ³ã‚«ãƒ¼å–å¾—
                let goldenAnchors = [null, null];
                for (let t = video.duration - 0.1; t > 0; t -= 0.4) {
                    video.currentTime = t;
                    await new Promise(r => video.onseeked = r);
                    const res = faceLandmarker.detect(video);
                    if (res.faceLandmarks && res.faceLandmarks.length >= 2) {
                        const sorted = [...res.faceLandmarks].sort((a,b) => a[4].x - b[4].x);
                        goldenAnchors = sorted.map(lm => ({ x: lm[4].x, y: lm[4].y }));
                        addLog("äºŒäººã®ä½ç½®ã‚’ãƒ­ãƒƒã‚¯ã‚ªãƒ³ã—ã¾ã—ãŸã€‚");
                        break;
                    }
                }
                if (!goldenAnchors[0]) goldenAnchors = [{x:0.3, y:0.5}, {x:0.7, y:0.5}];

                addLog("æ‰‹é †2: ã‚¢ãƒ³ã‚«ãƒ¼å‘¨è¾ºã‚’ã‚ºãƒ¼ãƒ è§£æã—ã€å…‰é‡ã‚’è£œæ­£ã—ã¾ã™...");
                const zCanvas = document.createElement('canvas'); zCanvas.width = 640; zCanvas.height = 640;
                const zCtx = zCanvas.getContext('2d');
                const totalSteps = Math.floor(video.duration * SCAN_FPS);

                for (let i = 0; i <= totalSteps; i++) {
                    const ts = i / SCAN_FPS;
                    video.currentTime = ts;
                    await new Promise(r => { video.onseeked = r; setTimeout(r, 800); });
                    await new Promise(r => requestAnimationFrame(r));

                    let foundInFrame = [];
                    for (let id = 0; id < 2; id++) {
                        const anchor = goldenAnchors[id];
                        const rw = canvas.width * 0.45, rh = canvas.height * 0.55;
                        const rx = Math.max(0, Math.min(canvas.width - rw, anchor.x * canvas.width - rw/2));
                        const ry = Math.max(0, Math.min(canvas.height - rh, anchor.y * canvas.height - rh/2));

                        zCtx.clearRect(0,0,640,640);
                        zCtx.filter = "brightness(1.4) contrast(1.7)";
                        zCtx.drawImage(video, rx, ry, rw, rh, 0, 0, 640, 640);

                        const results = faceLandmarker.detect(zCanvas);
                        if (results.faceLandmarks && results.faceLandmarks[0]) {
                            let f = extractMetrics(results.faceLandmarks[0]);
                            f.px = rx + (f.nx_local * rw); f.py = ry + (f.ny_local * rh);
                            f.pScale = f.s_local * rw; f.lane = id;
                            foundInFrame.push(f);
                        }
                    }
                    frameSequence.push({ time: ts, faces: foundInFrame });
                    progressFill.style.width = Math.floor((i / totalSteps) * 100) + "%";
                }

                finalizeSmoothTracks();
                addLog("å…¨è§£æå®Œäº†ã€‚");
                progressBox.style.display = "none"; downloadBtn.style.display = "block";
                video.currentTime = 0; video.play();
                requestAnimationFrame(liveLoop);
            };
        }

        // --- 2. è§’é€Ÿåº¦åˆ¶é™ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚° ï¼‹ è£œé–“ ---
        function finalizeSmoothTracks() {
            let tracks = [[], []]; let lastData = [null, null];

            frameSequence.forEach((frame, idx) => {
                let assigned = [null, null];
                frame.faces.forEach(f => { if (!assigned[f.lane]) assigned[f.lane] = f; });

                for(let id=0; id<2; id++) {
                    let f = assigned[id];
                    let prev = lastData[id];

                    if (f && prev) {
                        // ç‰©ç†åˆ¶ç´„ï¼šæ€¥æ¿€ãªå›è»¢ã‚„ãƒ”ãƒƒãƒã®å¤‰åŒ–ã‚’åˆ¶é™ (maxDelta)
                        f.yaw = smoothValue(prev.yaw, f.yaw, 0.08);
                        f.pitch = smoothValue(prev.pitch, f.pitch, 0.08);
                        f.angle = smoothAngle(prev.angle, f.angle, 0.12);
                    }

                    if (!f && prev && prev.life > 0) {
                        assigned[id] = { ...prev, life: prev.life - 1, isGhost: true };
                    } else if (f) {
                        f.life = 180; f.isGhost = false;
                    }
                    tracks[id].push(assigned[id]);
                    if (assigned[id]) lastData[id] = assigned[id];
                }
            });

            // æ¬ æè£œé–“
            tracks.forEach(track => {
                for (let i = 1; i < track.length - 1; i++) {
                    if (!track[i]) {
                        let p = i - 1; while(p >= 0 && !track[p]) p--;
                        let n = i + 1; while(n < track.length && !track[n]) n++;
                        if (p >= 0 && n < track.length && (n - p) < 180) {
                            track[i] = lerpPro(track[p], track[n], (i - p) / (n - p));
                        }
                    }
                }
            });
            frameSequence.forEach((f, i) => f.optimizedFaces = [tracks[0][i], tracks[1][i]]);
        }

        function smoothValue(prev, curr, maxDelta) {
            const d = curr - prev;
            return prev + Math.max(-maxDelta, Math.min(maxDelta, d));
        }

        function smoothAngle(prev, curr, maxDelta) {
            let d = curr - prev;
            while (d > Math.PI) d -= Math.PI * 2;
            while (d < -Math.PI) d += Math.PI * 2;
            return prev + Math.max(-maxDelta, Math.min(maxDelta, d));
        }

        function extractMetrics(lm) {
            const nx = (lm[4].x + lm[1].x + lm[195].x) / 3, ny = (lm[4].y + lm[1].y + lm[195].y) / 3;
            return { nx_local: nx, ny_local: ny, s_local: Math.abs(lm[454].x - lm[234].x), angle: Math.atan2((lm[263].y-lm[33].y),(lm[263].x-lm[33].x)), yaw: (lm[4].x - (lm[33].x+lm[263].x)*0.5)/(Math.abs(lm[454].x-lm[234].x)*0.5||1), pitch: Math.atan2(lm[152].z-lm[4].z, lm[152].y-lm[4].y) };
        }

        function lerpPro(a, b, t) {
            let d = b.angle - a.angle; while(d > Math.PI) d -= Math.PI*2; while(d < -Math.PI) d += Math.PI*2;
            return { px: a.px+(b.px-a.px)*t, py: a.py+(b.py-a.py)*t, pScale: a.pScale+(b.pScale-a.pScale)*t, angle: a.angle+d*t, yaw: a.yaw, pitch: a.pitch, isGhost: true };
        }

        function liveLoop() {
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            const frame = frameSequence.find(f => f.time >= video.currentTime) || frameSequence[frameSequence.length-1];
            if (frame) frame.optimizedFaces.forEach(face => { if (face) drawFinalMuzzle(face); });
            if (!video.paused && !video.ended) requestAnimationFrame(liveLoop);
        }

        function drawFinalMuzzle(f) {
            const px = f.px, py = f.py;
            const aspect = muzzleImg.width / muzzleImg.height;
            const yaw = Math.max(-1.2, Math.min(1.2, f.yaw));
            const baseSizePx = f.pScale * 0.95;
            const sxL = 1 - Math.max(0, -yaw)*0.55, sxR = 1 - Math.max(0, yaw)*0.55;
            const scaleY = (1 - Math.abs(yaw) * 0.15) * (1.0 + (f.pitch - 0.5) * 0.35);
            const dw = baseSizePx, dh = dw / aspect;

            ctx.save();
            ctx.translate(px + yaw * dw * 0.16, py); ctx.rotate(f.angle || 0);
            ctx.globalAlpha = 1.0; 
            const imgW = muzzleImg.width, imgH = muzzleImg.height;
            ctx.save(); ctx.scale(sxL, scaleY);
            ctx.drawImage(muzzleImg, 0, 0, imgW/2, imgH, -dw/2, -dh/2 + (dh*0.1), dw/2, dh);
            ctx.restore();
            ctx.save(); ctx.scale(sxR, scaleY);
            ctx.drawImage(muzzleImg, imgW/2, 0, imgW/2, imgH, 0, -dh/2 + (dh*0.1), dw/2, dh);
            ctx.restore();
            ctx.restore();
        }

        // ä¿å­˜æ©Ÿèƒ½ï¼ˆã‚ªãƒ¼ãƒ‡ã‚£ã‚ªçµ±åˆï¼‰
        downloadBtn.onclick = async () => {
            addLog("éŸ³å£°å…¥ã‚Šå‹•ç”»ã‚’ç”Ÿæˆä¸­...");
            const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            const destination = audioCtx.createMediaStreamDestination();
            const source = audioCtx.createMediaElementSource(video);
            source.connect(destination); source.connect(audioCtx.destination);
            const stream = canvas.captureStream(30);
            const combined = new MediaStream([...stream.getVideoTracks(), ...destination.stream.getAudioTracks()]);
            const recorder = new MediaRecorder(combined, { mimeType: 'video/webm;codecs=vp9', videoBitsPerSecond: 12000000 });
            const chunks = [];
            recorder.ondataavailable = e => chunks.push(e.data);
            recorder.onstop = async () => {
                const blob = new Blob(chunks, {type:'video/webm'});
                const file = new File([blob], "cat_muzzle.mp4", {type:"video/mp4"});
                if (navigator.share) await navigator.share({ files: [file] });
                else { const a = document.createElement('a'); a.href = URL.createObjectURL(blob); a.download = "result.mp4"; a.click(); }
                addLog("ä¿å­˜å®Œäº†ï¼");
            };
            video.currentTime = 0; video.muted = false; recorder.start(); video.play();
            const exportRender = () => {
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                const frame = frameSequence.find(f => f.time >= video.currentTime) || frameSequence[frameSequence.length-1];
                if (frame) frame.optimizedFaces.forEach(face => { if (face) drawFinalMuzzle(face); });
                if (video.ended) setTimeout(() => recorder.stop(), 500); else requestAnimationFrame(exportRender);
            };
            exportRender();
        };

        init();
    </script>
</body>
</html>