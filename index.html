<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>Cat Muzzle AI - Professional Studio v115 Stable</title>
    <style>
        body { font-family: 'Segoe UI', sans-serif; background: #0a0a0a; color: #eee; text-align: center; margin: 0; padding: 10px; }
        .card { background: #1a1a1a; padding: 25px; border-radius: 24px; max-width: 850px; margin: auto; box-shadow: 0 10px 40px rgba(0,0,0,0.5); }
        #log { background: #000; color: #00ff66; font-family: 'Consolas', monospace; font-size: 11px; padding: 10px; height: 120px; overflow-y: auto; text-align: left; border-radius: 12px; margin-bottom: 20px; border: 1px solid #333; white-space: pre-wrap; }
        .preview-box { position: relative; width: 100%; background: #000; border-radius: 16px; border: 1px solid #333; overflow: hidden; display: flex; flex-direction: column; align-items: center; min-height: 400px; }
        canvas { width: 100%; height: auto; display: block; image-rendering: -webkit-optimize-contrast; }
        .btn { padding: 16px 32px; background: #6200ee; color: white; border: none; border-radius: 12px; font-weight: bold; cursor: pointer; font-size: 16px; width: 85%; margin: 10px 0; transition: 0.3s; }
        .btn:hover:not(:disabled) { background: #7c4dff; transform: translateY(-2px); }
        .btn:disabled { background: #333; color: #777; cursor: wait; }
        .progress-box { width: 90%; margin: 15px auto; display: none; }
        .progress-bar { width: 100%; background: #333; height: 10px; border-radius: 5px; overflow: hidden; }
        #progressFill { width: 0%; background: #00e676; height: 100%; transition: width 0.2s; }
        #progressLabel { font-size:13px; margin-top:8px; color:#00e676; font-weight:bold; }
        #downloadBtn { background: #00c853; display: none; }
        #replayBtn { background: #007bff; display: none; }
    </style>
</head>
<body>
    <div class="card">
        <h2 style="margin-top:0;">ğŸ± CAT MUZZLE AI <span style="font-size:12px; color:#7c4dff;">v115 FINAL-STABLE</span></h2>
        <div id="log">ãƒ­ã‚°: ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ä¸­...</div>
        
        <input type="file" id="fileInput" accept="image/*,video/*" hidden>
        <button id="uploadBtn" class="btn" disabled>ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...</button>

        <div class="progress-box" id="progressBox">
            <div class="progress-bar"><div id="progressFill"></div></div>
            <div id="progressLabel">æº–å‚™ä¸­...</div>
        </div>

        <div class="preview-box">
            <canvas id="canvas"></canvas>
            <video id="video" playsinline muted style="display:none;"></video>
        </div>

        <button id="replayBtn" class="btn">ğŸ”„ ã‚‚ã†ä¸€åº¦å†ç”Ÿã™ã‚‹</button>
        <button id="downloadBtn" class="btn">ğŸ“¥ éŸ³å£°å…¥ã‚Šå‹•ç”»ã‚’ä¿å­˜ï¼ˆã‚«ãƒ¡ãƒ©ãƒ­ãƒ¼ãƒ«ï¼‰</button>
    </div>

    <script type="module">
        import { FaceLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";

        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const video = document.getElementById('video');
        const fileInput = document.getElementById('fileInput');
        const uploadBtn = document.getElementById('uploadBtn');
        const downloadBtn = document.getElementById('downloadBtn');
        const replayBtn = document.getElementById('replayBtn');
        const progressBox = document.getElementById('progressBox');
        const progressFill = document.getElementById('progressFill');
        const progressLabel = document.getElementById('progressLabel');
        const logArea = document.getElementById('log');

        let faceLandmarker, muzzleImg = new Image(); muzzleImg.src = "muzzle.png"; 
        let frameData = [], isLooping = false, isExporting = false, audioCtx, audioSource, audioDest;
        const SCAN_FPS = 12;

        function addLog(msg) { logArea.innerText += `> ${msg}\n`; logArea.scrollTop = logArea.scrollHeight; }

        async function init() {
            try {
                const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
                faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
                    baseOptions: { modelAssetPath: `./models/face_landmarker.task`, delegate: "CPU" },
                    runningMode: "IMAGE", numFaces: 1, minFaceDetectionConfidence: 0.1
                });
                addLog("ã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº†ã€‚");
                uploadBtn.disabled = false; uploadBtn.innerText = "å‹•ç”»ã‚’é¸æŠã—ã¦è§£æé–‹å§‹";
                uploadBtn.onclick = () => fileInput.click();
            } catch (e) { addLog("åˆæœŸåŒ–å¤±æ•—: " + e.message); }
        }

        fileInput.onchange = (e) => {
            const file = e.target.files[0];
            if (!file) return;
            downloadBtn.style.display = "none"; replayBtn.style.display = "none";
            startDeepAnalysis(URL.createObjectURL(file));
        };

        // --- 1. é«˜ç²¾åº¦ãƒ»çµ¶å¯¾ã«æ­¢ã¾ã‚‰ãªã„è§£æãƒ—ãƒ­ã‚»ã‚¹ ---
        async function startDeepAnalysis(url) {
            addLog("æ‰‹é †1: æˆåŠŸåœ°ç‚¹ã®ç‰¹å®šä¸­...");
            video.src = url; video.load();
            video.onloadedmetadata = async () => {
                canvas.width = video.videoWidth; canvas.height = video.videoHeight;
                frameData = []; progressBox.style.display = "block";
                
                let goldenAnchors = [null, null];
                // æœ€å¾Œã‹ã‚‰5ç§’é–“é¡ã£ã¦ã‚¢ãƒ³ã‚«ãƒ¼ã‚’æ¢ã™
                for (let t = video.duration - 0.1; t > 0; t -= 0.5) {
                    video.currentTime = t;
                    const seekOk = await waitVideoSeekSafe();
                    if (!seekOk) continue;
                    const res = faceLandmarker.detect(video);
                    if (res.faceLandmarks && res.faceLandmarks.length >= 1) {
                        const sorted = [...res.faceLandmarks].sort((a,b) => a[4].x - b[4].x);
                        goldenAnchors = sorted.map(lm => ({ x: lm[4].x, y: lm[4].y }));
                        addLog("é¡”ã®ä½ç½®ã‚’ç‰¹å®šã—ã¾ã—ãŸã€‚");
                        break;
                    }
                    if (t < video.duration - 5) break;
                }
                if (!goldenAnchors[0]) goldenAnchors = [{x:0.3, y:0.5}, {x:0.7, y:0.5}];

                addLog("æ‰‹é †2: ã‚¢ãƒ³ã‚«ãƒ¼ã‚ºãƒ¼ãƒ è§£æä¸­...");
                const zCanvas = document.createElement('canvas'); zCanvas.width = 640; zCanvas.height = 640;
                const zCtx = zCanvas.getContext('2d');
                const totalSteps = Math.floor(video.duration * SCAN_FPS);

                for (let i = 0; i <= totalSteps; i++) {
                    const ts = i / SCAN_FPS;
                    video.currentTime = ts;
                    
                    const seekOk = await waitVideoSeekSafe();
                    // ã‚·ãƒ¼ã‚¯å¾Œã€ã•ã‚‰ã«ãƒ–ãƒ©ã‚¦ã‚¶ã«æç”»ã•ã›ã‚‹æ™‚é–“ã‚’æ˜ç¤ºçš„ã«ä¸ãˆã‚‹
                    await new Promise(r => setTimeout(r, 20)); 

                    let foundInFrame = [];
                    if (seekOk) {
                        try {
                            for (let id = 0; id < 2; id++) {
                                const anchor = goldenAnchors[id];
                                const rw = canvas.width * 0.45, rh = canvas.height * 0.55;
                                const rx = Math.max(0, Math.min(canvas.width - rw, anchor.x * canvas.width - rw/2));
                                const ry = Math.max(0, Math.min(canvas.height - rh, anchor.y * canvas.height - rh/2));
                                zCtx.clearRect(0,0,640,640);
                                zCtx.filter = "brightness(1.3) contrast(1.6)";
                                zCtx.drawImage(video, rx, ry, rw, rh, 0, 0, 640, 640);
                                const results = faceLandmarker.detect(zCanvas);
                                if (results.faceLandmarks && results.faceLandmarks[0]) {
                                    let f = extractMetrics(results.faceLandmarks[0]);
                                    f.px = rx + (f.nx_local * rw); f.py = ry + (f.ny_local * rh);
                                    f.pScale = f.s_local * rw; f.lane = id;
                                    foundInFrame.push(f);
                                }
                            }
                        } catch(e) { /* ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã®ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ã—ã¦æ¬¡ã«é€²ã‚€ */ }
                    }

                    frameData.push({ time: ts, faces: foundInFrame });
                    const percent = Math.floor((i / totalSteps) * 100);
                    progressFill.style.width = percent + "%";
                    progressLabel.innerText = `è§£æä¸­: ${percent}% (${i}/${totalSteps})`;
                }

                finalizeTracks();
                addLog("è§£æå®Œäº†ï¼ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆã—ã¾ã™ã€‚");
                progressBox.style.display = "none"; downloadBtn.style.display = "block";
                startPlayback();
            };
        }

        // ã‚·ãƒ¼ã‚¯å¾…æ©Ÿã®æ ¸å¿ƒï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
        async function waitVideoSeekSafe() {
            return new Promise(resolve => {
                const timeout = setTimeout(() => {
                    resolve(video.readyState >= 2); // 1ç§’çµŒã£ãŸã‚‰ãã®æ™‚ã®çŠ¶æ…‹ã§æ¬¡ã¸
                }, 1000);
                const onSeeked = () => {
                    clearTimeout(timeout);
                    video.removeEventListener('seeked', onSeeked);
                    resolve(true);
                };
                video.addEventListener('seeked', onSeeked);
                // ã™ã§ã«å®Œäº†ã—ã¦ã„ã‚‹å ´åˆ
                if (video.readyState >= 3) {
                    clearTimeout(timeout);
                    video.removeEventListener('seeked', onSeeked);
                    resolve(true);
                }
            });
        }

        function extractMetrics(lm) {
            const nx = (lm[4].x + lm[1].x + lm[195].x) / 3, ny = (lm[4].y + lm[1].y + lm[195].y) / 3;
            return { nx_local: nx, ny_local: ny, s_local: Math.abs(lm[454].x - lm[234].x), angle: Math.atan2((lm[263].y-lm[33].y),(lm[263].x-lm[33].x)), yaw: (lm[4].x - (lm[33].x+lm[263].x)*0.5)/(Math.abs(lm[454].x-lm[234].x)*0.5||1), pitch: Math.atan2(lm[152].z-lm[4].z, lm[152].y-lm[4].y) };
        }

        function finalizeTracks() {
            let tracks = [[], []]; let lastData = [null, null];
            frameData.forEach((frame, idx) => {
                let assigned = [null, null];
                frame.faces.forEach(f => { if (!assigned[f.lane]) assigned[f.lane] = f; });
                for(let id=0; id<2; id++) {
                    let f = assigned[id]; let prev = lastData[id];
                    if (f && prev) {
                        f.yaw = prev.yaw + Math.max(-0.08, Math.min(0.08, f.yaw-prev.yaw));
                        f.pitch = prev.pitch + Math.max(-0.08, Math.min(0.08, f.pitch-prev.pitch));
                        let dAng = f.angle - prev.angle;
                        while (dAng > Math.PI) dAng -= Math.PI * 2; while (dAng < -Math.PI) dAng += Math.PI * 2;
                        f.angle = prev.angle + Math.max(-0.12, Math.min(0.12, dAng));
                    }
                    if (!f && prev && prev.life > 0) assigned[id] = { ...prev, life: prev.life - 1, isGhost: true };
                    else if (f) { f.life = 120; f.isGhost = false; }
                    tracks[id].push(assigned[id]); if (assigned[id]) lastData[id] = assigned[id];
                }
            });
            tracks.forEach(track => {
                for (let i = 1; i < track.length - 1; i++) {
                    if (!track[i]) {
                        let p = i - 1; while(p >= 0 && !track[p]) p--;
                        let n = i + 1; while(n < track.length && !track[n]) n++;
                        if (track[p] && track[n] && (n-p)<150) track[i] = lerpPro(track[p], track[n], (i-p)/(n-p));
                    }
                }
            });
            frameData.forEach((f, i) => f.optimizedFaces = [tracks[0][i], tracks[1][i]]);
        }
        function lerpPro(a,b,t) { return { px: a.px+(b.px-a.px)*t, py: a.py+(b.py-a.py)*t, pScale: a.pScale+(b.pScale-a.pScale)*t, angle: a.angle, yaw: a.yaw, pitch: a.pitch, isGhost: true }; }

        function startPlayback() { video.currentTime = 0; video.play(); isLooping = true; requestAnimationFrame(liveLoop); }
        video.onended = () => { isLooping = false; replayBtn.style.display = "block"; };
        replayBtn.onclick = () => { replayBtn.style.display = "none"; startPlayback(); };

        function liveLoop() {
            if (!isLooping || isExporting) return;
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            const frame = frameData.find(f => f.time >= video.currentTime) || frameData[frameData.length-1];
            if (frame) frame.optimizedFaces.forEach(face => { if (face) drawFinalMuzzle(face); });
            requestAnimationFrame(liveLoop);
        }

        function drawFinalMuzzle(f) {
            const px = f.px, py = f.py;
            const aspect = muzzleImg.width / muzzleImg.height;
            const yaw = Math.max(-1.2, Math.min(1.2, f.yaw));
            const dw = f.pScale * 0.95, dh = dw / aspect;
            const sxL = 1-Math.max(0,-yaw)*0.55, sxR = 1-Math.max(0,yaw)*0.55;
            const scaleY = (1-Math.abs(yaw)*0.15)*(1+(f.pitch-0.5)*0.35);
            ctx.save();
            ctx.translate(px + yaw * dw * 0.16, py); ctx.rotate(f.angle);
            ctx.globalAlpha = 1.0; 
            const imgW = muzzleImg.width, imgH = muzzleImg.height;
            ctx.save(); ctx.scale(sxL, scaleY); ctx.drawImage(muzzleImg, 0,0,imgW/2,imgH, -dw/2,-dh/2+(dh*0.1), dw/2,dh); ctx.restore();
            ctx.save(); ctx.scale(sxR, scaleY); ctx.drawImage(muzzleImg, imgW/2,0,imgW/2,imgH, 0,-dh/2+(dh*0.1), dw/2,dh); ctx.restore();
            ctx.restore();
        }

        // ä¿å­˜ãƒ­ã‚¸ãƒƒã‚¯
        downloadBtn.onclick = async () => {
            addLog("å®Ÿæ™‚é–“ã§æ›¸ãå‡ºã—ä¸­... å†ç”ŸãŒçµ‚ã‚ã‚‹ã¾ã§ãŠå¾…ã¡ãã ã•ã„ã€‚");
            downloadBtn.disabled = true; isExporting = true; isLooping = false;
            if (!audioCtx) {
                audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                audioDest = audioCtx.createMediaStreamDestination();
                audioSource = audioCtx.createMediaElementSource(video);
                audioSource.connect(audioDest); audioSource.connect(audioCtx.destination);
            }
            await audioCtx.resume();
            const combined = new MediaStream([...canvas.captureStream(30).getVideoTracks(), ...audioDest.stream.getAudioTracks()]);
            const recorder = new MediaRecorder(combined, { mimeType: 'video/webm;codecs=vp9', videoBitsPerSecond: 12000000 });
            const chunks = [];
            recorder.ondataavailable = e => { if(e.data.size > 0) chunks.push(e.data); };
            recorder.onstop = async () => {
                const blob = new Blob(chunks, { type: 'video/webm' });
                const file = new File([blob], "cat_muzzle.mp4", { type: "video/mp4" });
                if (navigator.share) await navigator.share({ files: [file] });
                else { const a = document.createElement('a'); a.href = URL.createObjectURL(blob); a.download = "result.mp4"; a.click(); }
                addLog("ä¿å­˜å®Œäº†ï¼"); downloadBtn.disabled = false; isExporting = false;
            };
            video.currentTime = 0; video.muted = false; recorder.start(); video.play();
            const exportProcess = () => {
                if (!isExporting) return;
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                const frame = frameData.find(f => f.time >= video.currentTime) || frameData[frameData.length-1];
                if (frame) frame.optimizedFaces.forEach(face => { if (face) drawFinalMuzzle(face); });
                if (video.ended) setTimeout(() => recorder.stop(), 500); else requestAnimationFrame(exportProcess);
            };
            exportProcess();
        };

        async function processImage(url) { /* ç”»åƒå‡¦ç† */ }

        init();
    </script>
</body>
</html>